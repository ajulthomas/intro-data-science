---
title: "Final Assignment, Task 3"
author: "Put your name"
date: "2023-11-2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Task 3: Data-Driven Modelling: 	(15 marks)

1. Based on the covid19_data dataframe, that you have wrangled and used in the previous tasks, create a separate dataframe named "cor_data" with the data of these variables (CumCases, CumTests, Population, GDP, GDPCapita) variables.

    [Hint: you can use select function on the covid19_data dataframe]

```{r}
# The code and code description of this component go below here

cor_data <- covid19_data %>%
  select(CumCases, CumTests, Population, GDP, GDPCapita)

```

2. Compute the correlation matrix between the variables of the “cor_data” and visualise this correlation matrix.

```{r}
# The code and code description of this component go below here
library(GGally)

cor_matrix <- cor(cor_data, use = "complete.obs") # using complete.obs to handle any NA values
cor_matrix
ggcorr(cor_data, label = TRUE, label_alpha = TRUE)

```

3. visualize the distribution of the cumulative cases in the cor_data with and without changing the scale of the x axis to log transformation.

```{r}
# The code and code description of this component go below here
# with original scale
ggplot(cor_data, aes(x = CumCases)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Cumulative Cases",
       x = "Cumulative Cases",
       y = "Frequency")


ggplot(cor_data, aes(x = CumCases)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  scale_x_log10() + # Log transformation
  theme_minimal() +
  labs(title = "Log-Transformed Distribution of Cumulative Cases",
       x = "Log of Cumulative Cases",
       y = "Frequency")


```

4. Divide the cor_data into training and testing, where training data represent 65% of the number of rows.

```{r}
# The code and code description of this component go below here
set.seed(123)
# Calculate the size of the training set
training_size <- floor(0.65 * nrow(cor_data))

# Sample indices for the training set
training_indices <- sample(seq_len(nrow(cor_data)), size = training_size)

# Create the training dataset
training_set <- cor_data[training_indices, ]

# Create the testing dataset
testing_set <- cor_data[-training_indices, ]

# Check the number of rows in each set
nrow(training_set)  # Should be around 65% of the total
nrow(testing_set)   # Should be around 35% of the total

```

5. Train a linear regression model to predict cumulative cases from the GDP of the countries. Then, evaluate this model on the test data and print the root mean square error value.

```{r}
# The code and code description of this component go below here
# 2. Training the Model
model <- lm(CumCases ~ GDP, data = training_set)

predictions <- 
  predict(model, testing_set)

library(Metrics)

actual <- 
  testing_set$CumCases

rmse(actual, predictions)

sqrt(mean((predictions-actual)^2))

```

6. Train another linear regression model to predict cumulative cases from all the other variables. Then, evaluate this model on the test data and print the root mean square error value.

```{r}
# The code and code description of this component go below here
model_all <- lm(CumCases ~ ., data = training_set)
prediction_all <- 
  predict(model_all, testing_set)

actual <- 
  testing_set$CumCases

rmse(actual, prediction_all)

sqrt(mean((prediction_all-actual)^2))

```

7. Interpret the two models and write a small report of highlighting the differences between using the two models. For example, in which cases we should use the first model and in which cases the second one is better to use.

**Interpretation goes below here**:
- 
- 
- 
-

----

**Task 3 final Report**: Highlight the output (Description, graphs and statistics) that have been generated by writing and running the code of the above components. 

----

*** 